{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95a7abd0",
   "metadata": {},
   "source": [
    "# Unit 2: Fisheries Collapse Module Overview\n",
    "\n",
    "This module will focus on examining a crucial global issue and important scientific debate about the state of global fisheries.  In this module we will seek to reproduce some of the most widely cited examples of species collapse ever, and examine the evidence behind an influential and widely cited paper on global fisheries, [Worm et al 2006](http://doi.org/10.1126/science.1132294).  However, rather than use the limited data available to Boris Worm and colleagues in 2006, we will be drawing from the best and most recent stock asssement data available today to see how those patterns have faired.  \n",
    "\n",
    "In this module we will also begin to master one of the most important concepts in data science: manipulation of tabular data using relational database concepts. Instead of working with independent data.frames, we will be working with a large relational database which contains many different tables of different sizes and shapes, but that all all related to each other through a series of different ids.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ba8492-439d-46f0-b423-f6346d9cba53",
   "metadata": {},
   "source": [
    "## The Database\n",
    "\n",
    "We will use data from the RAM Legacy Stock Assessment Database.  In order to better introduce some important emerging technologies, we will be accessing these data directly from a relatively new platform that is now playing a key role in data sharing in machine learning communities, with the memorable name, HuggingFace.  We will be streaming data from <https://huggingface.co/datasets/cboettig/ram_fisheries/tree/main/v4.65>.  We will have more to say about this approach as we progress.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13f9198-5cc5-4af7-9853-f08fce59dac8",
   "metadata": {},
   "source": [
    "## Researcher Spotlight: Daniel Pauly\n",
    "\n",
    "Science is done by real people.  There are many influential and colorful characters in the global fisheries debate.  I want to highlight Professor Pauly not just because he is so famous, but as an early believer in Open Science and Data Science, before we had either of those words.  His contributions in making fisheries data more open were ground breaking for their time.  I'm also indebted to Professor Pauly whom I had the privilege to meet when I was a junior scientist who had only recently released one of my first software packages, aimed at making data from FishBase more accessible. Academic researchers are typically defined by scientific publications, not software, so I was shocked that Pauly already knew of my software package, and that he encouraged me to continue developing software.  Even today that is not common advice, but I believed him, and it's probably a good reason I am where I am today.  Scientific textbooks and courses are often critiqued for failing to recognize the contributions of those from minority backgrounds, but as the texts are written on global change ecology, I think none will omit the works for Professor Pauly.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1b8944-1eda-4229-ad84-76facc592eac",
   "metadata": {},
   "source": [
    "## Science Introduction\n",
    "\n",
    "Background abbreviated documentary, features many of the leading authors on both sides https://vimeo.com/44104959"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffb87442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ibis\n",
    "from ibis import _\n",
    "import ibis.selectors as s\n",
    "import seaborn.objects as so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9387f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = ibis.duckdb.connect()\n",
    "\n",
    "base = \"https://huggingface.co/datasets/cboettig/ram_fisheries/resolve/main/v4.65/\"\n",
    "\n",
    "tsmetrics = con.read_csv(base + \"tsmetrics.csv\")\n",
    "timeseries = con.read_csv(base + \"timeseries.csv\")\n",
    "stock = con.read_csv(base + \"stock.csv\")\n",
    "assessment = con.read_csv(base + \"assessment.csv\")\n",
    "area = con.read_csv(base + \"area.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15dae898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tslong</th>\n",
       "      <th>tsunique</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>General total Catch (TC then TL, MT units only)</td>\n",
       "      <td>TCbest-MT</td>\n",
       "      <td>7442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Catch divided by mean catch</td>\n",
       "      <td>CdivMEANC-ratio</td>\n",
       "      <td>7442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total landings</td>\n",
       "      <td>TL-MT</td>\n",
       "      <td>6278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Total catch (i.e. landings + discards. Add lan...</td>\n",
       "      <td>TC-MT</td>\n",
       "      <td>4791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Catch or landings that is paired with TAC</td>\n",
       "      <td>Cpair-MT</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Total allowable catch</td>\n",
       "      <td>TAC-MT</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Catch divided by MSY</td>\n",
       "      <td>CdivMSY-ratio</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Recreational catch</td>\n",
       "      <td>RecC-MT</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tslong         tsunique     n\n",
       "0    General total Catch (TC then TL, MT units only)        TCbest-MT  7442\n",
       "1                        Catch divided by mean catch  CdivMEANC-ratio  7442\n",
       "2                                     Total landings            TL-MT  6278\n",
       "3  Total catch (i.e. landings + discards. Add lan...            TC-MT  4791\n",
       "4          Catch or landings that is paired with TAC         Cpair-MT   347\n",
       "5                              Total allowable catch           TAC-MT   311\n",
       "6                               Catch divided by MSY    CdivMSY-ratio   165\n",
       "7                                 Recreational catch          RecC-MT     8"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fish = (timeseries\n",
    "    #.drop(_.stocklong) an alternative to joining on the two columns \n",
    "    .rename(tsunique = \"tsid\")\n",
    "    .join(tsmetrics, \"tsunique\")\n",
    "    .join(stock, [\"stockid\",\"stocklong\"])\n",
    "    .join(assessment, \"assessid\")\n",
    ")\n",
    "\n",
    "cod_catch = (fish\n",
    "    .filter(_.tscategory == \"CATCH or LANDINGS\")\n",
    "    .filter(_.commonname == \"Atlantic cod\")\n",
    ")\n",
    "\n",
    "cod_catch.group_by(_.tslong, _.tsunique).agg(n = _.count()).order_by(_.n.desc()).execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbc9dc1-89db-4190-9683-9b7833e64207",
   "metadata": {},
   "source": [
    "\n",
    "# Exercise 1: Investigating the North-Atlantic Cod\n",
    "\n",
    "Now we are ready to dive into our data. First, We seek to replicate the following figure from the Millennium Ecosystem Assessment Project using the RAM data.\n",
    "\n",
    "![](https://espm-157.github.io/website-r/img/cod.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a426ad-d13a-4011-83f0-108e09036853",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88f42ebf-a09d-4cf9-8748-12bf7889c2db",
   "metadata": {},
   "source": [
    "# Excersise 2: Global Fisheries \n",
    "\n",
    "## Stock Collapses\n",
    "\n",
    "We seek to replicate the temporal trend in stock declines shown in [Worm et al 2006](http://doi.org/10.1126/science.1132294):\n",
    "\n",
    "![](https://espm-157.github.io/website-r/img/worm2006.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf887f4-6d94-45f4-8667-512b302d65c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
